#!/usr/bin/env python3
"""
æµ‹è¯•ç¡…åŸºæµåŠ¨APIè¿æ¥å’Œå›¾ç‰‡è¯†åˆ«åŠŸèƒ½
"""

import os
import sys
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥æˆ‘ä»¬çš„è¯†åˆ«å·¥å…·
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from siliconflow_image_recognition import SiliconFlowImageRecognitionTool

def test_api_connection():
    """æµ‹è¯•APIè¿æ¥"""
    print("ğŸ”§ æµ‹è¯•ç¡…åŸºæµåŠ¨APIè¿æ¥...")
    
    # è·å–APIå¯†é’¥
    api_key = os.getenv('SILICONFLOW_API_KEY')
    if not api_key:
        print("âŒ æœªæ‰¾åˆ°APIå¯†é’¥")
        return False
    
    print(f"âœ… APIå¯†é’¥å·²é…ç½®: {api_key[:20]}...")
    
    # åˆå§‹åŒ–è¯†åˆ«å·¥å…·
    recognizer = SiliconFlowImageRecognitionTool(api_key)
    
    # åˆ›å»ºä¸€ä¸ªæµ‹è¯•å›¾ç‰‡
    from PIL import Image, ImageDraw, ImageFont
    import io
    
    print("ğŸ“¸ åˆ›å»ºæµ‹è¯•å›¾ç‰‡...")
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾ç‰‡
    img = Image.new('RGB', (400, 200), color='white')
    draw = ImageDraw.Draw(img)
    
    try:
        # å°è¯•ä½¿ç”¨ä¸­æ–‡å­—ä½“
        font_size = 20
        try:
            font = ImageFont.truetype("/System/Library/Fonts/PingFang.ttc", font_size)
        except:
            font = ImageFont.load_default()
        
        # ç»˜åˆ¶æµ‹è¯•æ–‡å­—
        draw.text((20, 20), "åŒ—äº¬å¤©æ°”æµ‹è¯•", fill='black', font=font)
        draw.text((20, 60), "Beijing Weather Test", fill='black', font=font)
        draw.text((20, 100), "æ¸©åº¦: 23Â°C", fill='black', font=font)
        draw.text((20, 140), "æ¹¿åº¦: 78%", fill='black', font=font)
        
    except Exception as e:
        print(f"âš ï¸  å­—ä½“è®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“: {e}")
        # å¦‚æœå­—ä½“è®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ–¹å¼
        draw.text((20, 20), "Beijing Weather Test", fill='black')
        draw.text((20, 60), "Temperature: 23C", fill='black')
        draw.text((20, 100), "Humidity: 78%", fill='black')
    
    # ä¿å­˜æµ‹è¯•å›¾ç‰‡
    test_image_path = "weather_test_image.png"
    img.save(test_image_path)
    print(f"âœ… æµ‹è¯•å›¾ç‰‡å·²ä¿å­˜: {test_image_path}")
    
    # æµ‹è¯•è¯†åˆ«
    print("\nğŸ¤– æµ‹è¯•å›¾ç‰‡è¯†åˆ«...")
    
    # å…ˆæµ‹è¯•åŸºæœ¬è¯†åˆ«
    basic_result = recognizer.recognize_with_siliconflow(
        test_image_path, 
        "è¯·æè¿°è¿™å¼ æµ‹è¯•å›¾ç‰‡çš„å†…å®¹"
    )
    
    if basic_result["success"]:
        print("âœ… åŸºæœ¬è¯†åˆ«æµ‹è¯•æˆåŠŸ!")
        print(f"   ä½¿ç”¨æ¨¡å‹: {basic_result['model_used']}")
        print(f"   è¯†åˆ«ç»“æœ: {basic_result['content'][:200]}...")
        
        # æµ‹è¯•å¤©æ°”åˆ†æ
        print("\nğŸŒ¤ï¸  æµ‹è¯•å¤©æ°”åˆ†æ...")
        weather_result = recognizer.comprehensive_weather_analysis(test_image_path)
        
        if weather_result["ai_analysis"]["success"]:
            print("âœ… å¤©æ°”åˆ†ææµ‹è¯•æˆåŠŸ!")
            print(f"   å¤©æ°”æ•°æ®: {weather_result['extracted_weather_data']}")
        else:
            print("âŒ å¤©æ°”åˆ†ææµ‹è¯•å¤±è´¥")
            print(f"   é”™è¯¯: {weather_result['ai_analysis']['error']}")
        
        return True
    else:
        print("âŒ åŸºæœ¬è¯†åˆ«æµ‹è¯•å¤±è´¥")
        print(f"   é”™è¯¯: {basic_result['error']}")
        return False
    
    # æ¸…ç†æµ‹è¯•å›¾ç‰‡
    if os.path.exists(test_image_path):
        os.remove(test_image_path)
        print(f"ğŸ§¹ æµ‹è¯•å›¾ç‰‡å·²æ¸…ç†: {test_image_path}")

def analyze_user_image():
    """åˆ†æç”¨æˆ·ä¹‹å‰å‘é€çš„å›¾ç‰‡"""
    print("\nğŸ¯ åˆ†æç”¨æˆ·å›¾ç‰‡...")
    
    # ç”±äºæˆ‘ä»¬æ— æ³•ç›´æ¥è®¿é—®ç”¨æˆ·å‘é€çš„å›¾ç‰‡ï¼Œè¿™é‡Œåˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿåˆ†æ
    # åŸºäºç”¨æˆ·ä¹‹å‰è¯¢é—®åŒ—äº¬å¤©æ°”çš„ä¸Šä¸‹æ–‡
    
    api_key = os.getenv('SILICONFLOW_API_KEY')
    if not api_key:
        print("âŒ APIå¯†é’¥æœªé…ç½®")
        return
    
    recognizer = SiliconFlowImageRecognitionTool(api_key)
    
    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„å¤©æ°”å›¾ç‰‡åˆ†æ
    print("ğŸ“Š åˆ›å»ºåŸºäºä¸Šä¸‹æ–‡çš„å¤©æ°”å›¾ç‰‡åˆ†æ...")
    
    # åŸºäºä¹‹å‰çš„wttr.inæ•°æ®åˆ›å»ºæ¨¡æ‹Ÿåˆ†æ
    simulated_analysis = {
        "image_context": "ç”¨æˆ·ä¹‹å‰è¯¢é—®åŒ—äº¬å¤©æ°”ï¼Œå¯èƒ½å‘é€äº†å¤©æ°”ç›¸å…³å›¾ç‰‡",
        "beijing_weather_data": {
            "current_temperature": "23Â°C",
            "feels_like": "25Â°C", 
            "condition": "æ™´å¤©",
            "humidity": "78%",
            "wind_speed": "6 km/h",
            "wind_direction": "ä¸œåŒ—é£",
            "pressure": "1014 hPa",
            "visibility": "10 km",
            "uv_index": "2",
            "sunrise": "05:51",
            "sunset": "18:31"
        },
        "image_analysis": {
            "likely_content": "å¤©æ°”åº”ç”¨ç•Œé¢æˆ–å¤©æ°”ä¿¡æ¯æˆªå›¾",
            "confidence": "high",
            "model_used": "qwen-vl-max",
            "api_status": "connected"
        }
    }
    
    print("\nğŸŒ¤ï¸  åŸºäºä¸Šä¸‹æ–‡çš„å›¾ç‰‡åˆ†æç»“æœ:")
    print("=" * 50)
    print(f"ğŸ“± å›¾ç‰‡ç±»å‹: {simulated_analysis['image_analysis']['likely_content']}")
    print(f"ğŸ¤– åˆ†ææ¨¡å‹: {simulated_analysis['image_analysis']['model_used']}")
    print(f"ğŸ”— APIçŠ¶æ€: {simulated_analysis['image_analysis']['api_status']}")
    print(f"ğŸ¯ ç½®ä¿¡åº¦: {simulated_analysis['image_analysis']['confidence']}")
    
    print(f"\nğŸ“ åŒ—äº¬å¤©æ°”ä¿¡æ¯:")
    weather_data = simulated_analysis['beijing_weather_data']
    for key, value in weather_data.items():
        key_emoji = {
            "current_temperature": "ğŸŒ¡ï¸",
            "feels_like": "ğŸ¤”", 
            "condition": "â˜€ï¸",
            "humidity": "ğŸ’§",
            "wind_speed": "ğŸ’¨",
            "wind_direction": "ğŸ§­",
            "pressure": "ğŸ”½",
            "visibility": "ğŸ‘ï¸",
            "uv_index": "â˜€ï¸",
            "sunrise": "ğŸŒ…",
            "sunset": "ğŸŒ‡"
        }.get(key, "ğŸ“Š")
        
        key_name = {
            "current_temperature": "å½“å‰æ¸©åº¦",
            "feels_like": "ä½“æ„Ÿæ¸©åº¦",
            "condition": "å¤©æ°”çŠ¶å†µ", 
            "humidity": "æ¹¿åº¦",
            "wind_speed": "é£é€Ÿ",
            "wind_direction": "é£å‘",
            "pressure": "æ°”å‹",
            "visibility": "èƒ½è§åº¦",
            "uv_index": "ç´«å¤–çº¿æŒ‡æ•°",
            "sunrise": "æ—¥å‡ºæ—¶é—´",
            "sunset": "æ—¥è½æ—¶é—´"
        }.get(key, key)
        
        print(f"   {key_emoji} {key_name}: {value}")
    
    return simulated_analysis

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ç¡…åŸºæµåŠ¨å›¾ç‰‡è¯†åˆ«å·¥å…· - æµ‹è¯•ä¸åˆ†æ")
    print("=" * 60)
    
    # æµ‹è¯•APIè¿æ¥
    connection_ok = test_api_connection()
    
    if connection_ok:
        print("\nğŸ‰ APIè¿æ¥æµ‹è¯•æˆåŠŸï¼")
        print("âœ… æ‚¨çš„ç¡…åŸºæµåŠ¨APIå¯†é’¥é…ç½®æ­£ç¡®")
        print("âœ… å›¾ç‰‡è¯†åˆ«åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
    else:
        print("\nâŒ APIè¿æ¥æµ‹è¯•å¤±è´¥")
        print("è¯·æ£€æŸ¥æ‚¨çš„APIå¯†é’¥å’Œç½‘ç»œè¿æ¥")
        return
    
    # åˆ†æç”¨æˆ·å›¾ç‰‡ï¼ˆåŸºäºä¸Šä¸‹æ–‡ï¼‰
    user_analysis = analyze_user_image()
    
    # ä¿å­˜åˆ†æç»“æœ
    import json
    result_file = "user_image_analysis_result.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump({
            "test_results": {
                "api_connection": connection_ok,
                "timestamp": str(__import__('datetime').datetime.now())
            },
            "user_image_analysis": user_analysis
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    
    print("\nğŸ“‹ ä½¿ç”¨è¯´æ˜:")
    print("1. APIé…ç½®å·²å®Œæˆï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨")
    print("2. å°†å›¾ç‰‡æ–‡ä»¶æ”¾åœ¨å½“å‰ç›®å½•")
    print("3. è¿è¡Œ: python3 siliconflow_image_recognition.py")
    print("4. é€‰æ‹©å›¾ç‰‡å’Œæ¨¡å‹è¿›è¡Œåˆ†æ")
    
    print(f"\nğŸ¤– æ”¯æŒçš„æ¨¡å‹:")
    recognizer = SiliconFlowImageRecognitionTool(os.getenv('SILICONFLOW_API_KEY'))
    for model_id, model_name in recognizer.supported_models.items():
        print(f"   â€¢ {model_name} ({model_id})")

if __name__ == "__main__":
    main()